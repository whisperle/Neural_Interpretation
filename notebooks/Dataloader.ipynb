{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## webdataset from Mindeye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/scratch/cl6707/Shared_Datasets/NSD_MindEye\"\n",
    "nsd_root = \"/scratch/cl6707/Projects/neuro_interp/data/NSD/\"\n",
    "stim_root = nsd_root + \"nsddata_stimuli/stimuli/nsd/\"\n",
    "beta_root = nsd_root + \"nsddata_betas/ppdata/\"\n",
    "mask_root = nsd_root + \"nsddata/ppdata/\"\n",
    "subj = 1\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import webdataset as wds\n",
    "import PIL\n",
    "import argparse\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "local_rank = 0\n",
    "print(\"device:\",device)\n",
    "\n",
    "import utils\n",
    "from models import Clipper, OpenClipper, BrainNetwork, BrainDiffusionPrior, BrainDiffusionPriorOld, Voxel2StableDiffusionModel, VersatileDiffusionPriorNetwork\n",
    "\n",
    "if utils.is_interactive():\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "seed=42\n",
    "utils.seed_everything(seed=seed)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from src.file_utility import load_mask_from_nii, view_data\n",
    "from src.file_utility import save_stuff, flatten_dict, embed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "subj =1\n",
    "nsd_mindroot = '/scratch/cl6707/Shared_Datasets/NSD_MindEye'\n",
    "# np.load(nsd_mindroot + '/subj01_things.npy',allow_pickle=True)[2950]\n",
    "# # nsdgeneral = load_mask_from_nii('/scratch/cl6707/Projects/neuro_interp/data/NSD/nsddata/ppdata/subj01/func1pt8mm/brainmask.nii.gz')\n",
    "with h5py.File('/scratch/cl6707/Shared_Datasets/NSD_MindEye/subj01_3D_nsdgeneral.hdf5','r') as f:\n",
    "    for k in f.keys():\n",
    "        print(k, f[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject= 1\n",
    "voxel_roi_full  = load_mask_from_nii(mask_root + \"subj%02d/func1pt8mm/roi/prf-visualrois.nii.gz\"%subject)\n",
    "voxel_roi_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NSDAccess import NSDAccess\n",
    "nsd = NSDAccess('/scratch/cl6707/Projects/neuro_interp/data/NSD/')\n",
    "\n",
    "if subj == 1:\n",
    "    num_voxels = 15724\n",
    "elif subj == 2:\n",
    "    num_voxels = 14278\n",
    "elif subj == 3:\n",
    "    num_voxels = 15226\n",
    "elif subj == 4:\n",
    "    num_voxels = 13153\n",
    "elif subj == 5:\n",
    "    num_voxels = 13039\n",
    "elif subj == 6:\n",
    "    num_voxels = 17907\n",
    "elif subj == 7:\n",
    "    num_voxels = 12682\n",
    "elif subj == 8:\n",
    "    num_voxels = 14386\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pulling NSD webdataset data...')\n",
    "# Multi-GPU config #\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator(split_batches=False,mixed_precision='fp16')  \n",
    "print(\"PID of this process =\",os.getpid())\n",
    "print = accelerator.print # only print if local_rank=0\n",
    "device = accelerator.device\n",
    "print(\"device:\",device)\n",
    "num_devices = torch.cuda.device_count()\n",
    "if num_devices==0: num_devices = 1\n",
    "num_workers = num_devices\n",
    "print(accelerator.state)\n",
    "local_rank = accelerator.state.local_process_index\n",
    "world_size = accelerator.state.num_processes\n",
    "distributed = not accelerator.state.distributed_type == 'NO'\n",
    "print(\"distributed =\",distributed, \"num_devices =\", num_devices, \"local rank =\", local_rank, \"world size =\", world_size)\n",
    "\n",
    "\n",
    "\n",
    "train_url = \"{\" + f\"{data_path}/webdataset_avg_split/train/train_subj0{subj}_\" + \"{0..17}.tar,\" + f\"{data_path}/webdataset_avg_split/val/val_subj0{subj}_0.tar\" + \"}\"\n",
    "val_url = f\"{data_path}/webdataset_avg_split/test/test_subj0{subj}_\" + \"{0..1}.tar\"\n",
    "print(train_url,\"\\n\",val_url)\n",
    "meta_url = f\"{data_path}/webdataset_avg_split/metadata_subj0{subj}.json\"\n",
    "num_train = 8559 + 300\n",
    "num_val = 982\n",
    "\n",
    "print('Prepping train and validation dataloaders...')\n",
    "train_dl, val_dl, num_train, num_val = utils.get_dataloaders(\n",
    "    batch_size,'images',\n",
    "    num_devices=num_devices,\n",
    "    num_workers=num_workers,\n",
    "    train_url=train_url,\n",
    "    val_url=val_url,\n",
    "    meta_url=meta_url,\n",
    "    num_train=num_train,\n",
    "    num_val=num_val,\n",
    "    val_batch_size=300,\n",
    "    cache_dir=data_path, #\"/tmp/wds-cache\",\n",
    "    seed=seed,\n",
    "    voxels_key='3d_nsdgeneral.npy', # 'nsdgeneral.npy' (1d), 'wholebrain_3d.npy'(3d)\n",
    "    to_tuple=[\"voxels\", \"images\", \"coco\",\"trial\"],\n",
    "    local_rank=local_rank,\n",
    "    world_size=world_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_dl))\n",
    "annotation = np.load(nsd_mindroot + '/subj%02d_annot.npy'%subj,allow_pickle=True)\n",
    "things = np.load(nsd_mindroot + '/subj%02d_things.npy'%subj,allow_pickle=True)\n",
    "for s in sample:\n",
    "    print(s.shape)\n",
    "\n",
    "voxels, images, coco, trial = sample\n",
    "plt.imshow(images[0].permute(1,2,0))\n",
    "plt.show()\n",
    "print(\"annotation\",annotation[trial[0]])\n",
    "print(\"things\",things[trial[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"subj\",subj,\"num_voxels\",num_voxels)\n",
    "\n",
    "val_url = f\"{data_path}/webdataset_avg_split/test/test_subj0{subj}_\" + \"{0..1}.tar\"\n",
    "meta_url = f\"{data_path}/webdataset_avg_split/metadata_subj0{subj}.json\"\n",
    "num_train = 8559 + 300\n",
    "num_val = 982\n",
    "batch_size = val_batch_size = 1\n",
    "voxels_key = 'nsdgeneral.npy' # 1d inputs\n",
    "\n",
    "val_data = wds.WebDataset(val_url, resampled=False)\\\n",
    "    .decode(\"torch\")\\\n",
    "    .rename(images=\"jpg;png\", voxels=voxels_key, trial=\"trial.npy\", coco=\"coco73k.npy\", reps=\"num_uniques.npy\")\\\n",
    "    .to_tuple(\"voxels\", \"images\", \"coco\")\\\n",
    "    .batched(val_batch_size, partial=False)\n",
    "\n",
    "val_dl = torch.utils.data.DataLoader(val_data, batch_size=None, shuffle=False)\n",
    "\n",
    "\n",
    "# if self.view_3d:\n",
    "#     volume_voxel = np.nan_to_num(view_data(self.brain_nii_shape, voxel_idx, voxel_data ))\n",
    "# check that your data loader is working\n",
    "for val_i, (voxel, img_input, coco) in enumerate(val_dl):\n",
    "    print(\"idx\",val_i)\n",
    "    print(\"voxel.shape\",voxel.shape)\n",
    "    print(\"img_input.shape\",img_input.shape)\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivp",
   "language": "python",
   "name": "ivp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
